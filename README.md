# GESTSPEAK - SIGN LANGUAGE TO VOICE

This research aims to lower the barrier of day-to-day communication for disabled people by developing a user-friendly, cost-effective system by which we can determine the most appropriate character from the sign that the user is showing to the system About nine million people in the world are deaf and mute. Communication between differently abled people and general people has always been a challenging task but sign language helps them to communicate with other people. But not everyone understands sign language and here is where our system will come into the picture. Various machine learning algorithms have been investigated to facilitate pattern identification and processing. Advanced Python is used to train the model using the image features that were obtained. In response to the sign presented to the model, the trained model accurately predicts the words that are most appropriate using the datasets that are fed into the system. Words that are predicted are generated into a voice output. Sign language provides a way for speech impaired and hearing impaired people to communicate with other people. Instead of a voice, sign language uses gestures to communicate. Sign language is a standardised way of communication in which every word and alphabet is assigned to a distinct gesture The solution aims to assist those in need, ensuring social relevance by offering an interface that can help facilitate simple and unrestricted communication between a wide range of people.

![image](https://user-images.githubusercontent.com/72935128/206295487-0e25c737-9353-4e98-b8fb-0e5b38390cfb.png)

## Technology used
Computer vision and machine learning researchers are now conducting intensive research in the area of image-based hand gesture identification. With the aim of making human computer interaction (HCI) simpler and more natural without the use of additional devices, it is an area where many researchers are researching. Therefore, the main objective of research on gesture recognition is to develop systems that can recognise certain human gestures and use them, for instance, to convey information. For this, real-time hand detection and gesture identification are needed for vision-based hand gesture interfaces.
